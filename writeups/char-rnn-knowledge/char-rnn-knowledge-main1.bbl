\begin{thebibliography}{60}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Adi et~al.(2017)Adi, Kermany, Belinkov, Lavi, and
  Goldberg}]{Adi:etal:2017}
Yossi Adi, Einat Kermany, Yonatan Belinkov, Ofer Lavi, and Yoav Goldberg. 2017.
\newblock Fine-grained analysis of sentence embeddings using auxiliary
  prediction tasks.
\newblock In \emph{Proceedings of ICLR Conference Track}, Toulon, France.
\newblock Published online:
  \url{https://openreview.net/group?id=ICLR.cc/2017/conference}.

\bibitem[{Alishahi et~al.(2017)Alishahi, Barking, and
  Chrupa{\l}a}]{Alishahi:etal:2017}
Afra Alishahi, Marie Barking, and Grzegorz Chrupa{\l}a. 2017.
\newblock Encoding of phonology in a recurrent neural model of grounded speech.
\newblock In \emph{Proceedings of CoNLL}, pages 368--378, Vancouver, Canada.

\bibitem[{Bar(2007)}]{Bar:2007}
Moshe Bar. 2007.
\newblock The proactive brain: using analogies and associations to generate
  predictions.
\newblock \emph{Trends in Cognitive Science}, 11(7):280--289.

\bibitem[{Belinkov et~al.(2017)Belinkov, Durrani, Dalvi, Sajjad, and
  Glass}]{Belinkov:etal:2017}
Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, and James Glass.
  2017.
\newblock What do neural machine translation models learn about morphology?
\newblock In \emph{Proceedings of ACL}, pages 861--872, Vancouver, Canada.

\bibitem[{Bickel and {Z\'{u}\~{n}iga}(2017)}]{Bickel:Zuniga:2017}
Balthasar Bickel and Fernando {Z\'{u}\~{n}iga}. 2017.
\newblock The `word' in polysynthetic languages: Phonological and syntactic
  challenges.
\newblock In Michael Fortescue, Marianne Mithun, and Nicholas Evans, editors,
  \emph{Oxford Handbook of Polysynthesis}, pages 158--186. Oxford University
  Press, Oxford, UK.

\bibitem[{Bojanowski et~al.(2016)Bojanowski, Joulin, and
  Mikolov}]{Bojanowski:etal:2016}
Piotr Bojanowski, Armand Joulin, and Tomas Mikolov. 2016.
\newblock Alternative structures for character-level {RNNs}.
\newblock In \emph{Proceedings of ICLR Workshop Track}, San Juan, Puerto Rico.
\newblock Published online:
  \url{https://openreview.net/group?id=ICLR.cc/2016/workshop}.

\bibitem[{Brent(1999)}]{brent-efficient-1999}
Michael~R Brent. 1999.
\newblock An efficient, probabilistically sound algorithm for segmentation and
  word discovery.
\newblock \emph{Machine Learning}, 34(1-3):71--105.

\bibitem[{Bresnan et~al.(2016)Bresnan, Asudeh, Toivonen, and
  Wechsler}]{Bresnan:etal:2016}
Joan Bresnan, Ash Asudeh, Ida Toivonen, and Stephen Wechsler. 2016.
\newblock \emph{Lexical-Functional Syntax, 2nd ed.}
\newblock Blackwell, Malden, MA.

\bibitem[{Clark(2016)}]{Clark:2016}
Andy Clark. 2016.
\newblock \emph{Surfing Uncertainty}.
\newblock Oxford University Press, Oxford, UK.

\bibitem[{Cohen and Adams(2001)}]{cohen-algorithm-2001}
Paul Cohen and Niall Adams. 2001.
\newblock An algorithm for segmenting categorical time series into meaningful
  episodes.
\newblock In \emph{IDA '01 Proceedings of the 4th International Conference on
  Advances in Intelligent Data Analysis}, pages 198--207. Springer.

\bibitem[{Conneau et~al.(2018)Conneau, Kruszewski, Lample, Barrault, and
  Baroni}]{Conneau:etal:2018}
Alexis Conneau, Germ{\'a}n Kruszewski, Guillaume Lample, Lo{\"i}c Barrault, and
  Marco Baroni. 2018.
\newblock What you can cram into a single {\$}{\&}!{\#}* vector: Probing
  sentence embeddings for linguistic properties.
\newblock In \emph{Proceedings ACL}, pages 2126--2136, Melbourne, Australia.

\bibitem[{Cotterell et~al.(2018)Cotterell, Mielke, Eisner, and
  Roark}]{cotterell2018all}
Ryan Cotterell, Sebastian~J Mielke, Jason Eisner, and Brian Roark. 2018.
\newblock Are all languages equally hard to language-model?
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 2 (Short Papers)}, volume~2, pages 536--541.

\bibitem[{De~Marneffe et~al.(2006)De~Marneffe, MacCartney, Manning
  et~al.}]{de2006generating}
Marie-Catherine De~Marneffe, Bill MacCartney, Christopher~D Manning, et~al.
  2006.
\newblock Generating typed dependency parses from phrase structure parses.
\newblock In \emph{Proceedings of LREC}, volume~6, pages 449--454. Genoa Italy.

\bibitem[{Elman(1990)}]{Elman:1990}
Jeffrey Elman. 1990.
\newblock Finding structure in time.
\newblock \emph{Cognitive Science}, 14:179--211.

\bibitem[{Feng et~al.(2004)Feng, Chen, Deng, and Zheng}]{feng-accessor-2004}
Haodi Feng, Kang Chen, Xiaotie Deng, and Weimin Zheng. 2004.
\newblock Accessor variety criteria for {Chinese} word extraction.
\newblock \emph{Computational Linguistics}, 30(1):75--93.

\bibitem[{Frank et~al.(2013)Frank, Mathis, and Badecker}]{Frank:etal:2013}
Robert Frank, Donald Mathis, and William Badecker. 2013.
\newblock The acquisition of anaphora by simple recurrent networks.
\newblock \emph{Language Acquisition}, 20(3):181--227.

\bibitem[{Gerz et~al.(2018)Gerz, Vuli\'{c}, Ponti, Naradowsky, Reichart, and
  Korhonen}]{Gerz:etal:2018}
Daniela Gerz, Ivan Vuli\'{c}, Edoardo~Maria Ponti, Jason Naradowsky, Roi
  Reichart, and Anna Korhonen. 2018.
\newblock Language modeling for morphologically rich languages: Character-aware
  modeling for word-level prediction.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  6:451--465.

\bibitem[{Godin et~al.(2018)Godin, Demuynck, Dambre, {De Neve}, and
  Demeester}]{Godin:etal:2018}
Fr\'{e}deric Godin, Kris Demuynck, Joni Dambre, Wesley {De Neve}, and Thomas
  Demeester. 2018.
\newblock Explaining character-aware neural networks for word-level prediction:
  Do they discover linguistic rules?
\newblock In \emph{Proceedings of EMNLP}, Brussels, Belgium.
\newblock {I}n press.

\bibitem[{Goldberg(2005)}]{Goldberg:2005}
Adele Goldberg. 2005.
\newblock \emph{Constructions at work: The nature of generalization in
  language}.
\newblock Oxford University Press, Oxford, UK.

\bibitem[{Goldberg(2017)}]{Goldberg:2017}
Yoav Goldberg. 2017.
\newblock \emph{Neural Network Methods for Natural Language Processing}.
\newblock Morgan {\&} Claypool, San Francisco, CA.

\bibitem[{Goldwater et~al.(2009)Goldwater, Griffiths, and
  Johnson}]{goldwater-bayesian-2009}
Sharon Goldwater, Thomas~L. Griffiths, and Mark Johnson. 2009.
\newblock A {Bayesian} framework for word segmentation: {Exploring} the effects
  of context.
\newblock \emph{Cognition}, 112(1):21--54.

\bibitem[{Graves(2014)}]{DBLP:journals/corr/Graves13}
Alex Graves. 2014.
\newblock \href {https://arxiv.org/abs/1308.0850} {Generating sequences with
  recurrent neural networks}.
\newblock \emph{CoRR}, abs/1308.0850v5.

\bibitem[{Gulordava et~al.(2018)Gulordava, Bojanowski, Grave, Linzen, and
  Baroni}]{Gulordava:etal:2018}
Kristina Gulordava, Piotr Bojanowski, Edouard Grave, Tal Linzen, and Marco
  Baroni. 2018.
\newblock Colorless green recurrent networks dream hierarchically.
\newblock In \emph{Proceedings of NAACL}, pages 1195--1205, New Orleans, LA.

\bibitem[{Harris(1954)}]{harris-distributional-1954}
Zellig~S Harris. 1954.
\newblock Distributional structure.
\newblock \emph{Word}, 10(2-3):146--162.

\bibitem[{Hochreiter and Schmidhuber(1997)}]{Hochreiter:Schmidhuber:1997}
Sepp Hochreiter and J\"{u}rgen Schmidhuber. 1997.
\newblock Long short-term memory.
\newblock \emph{Neural Computation}, 9(8):1735--1780.

\bibitem[{Hupkes and Zuidema(2018)}]{DBLP:conf/ijcai/HupkesZ18}
Dieuwke Hupkes and Willem~H. Zuidema. 2018.
\newblock \href {https://doi.org/10.24963/ijcai.2018/796} {Visualisation and
  'diagnostic classifiers' reveal how recurrent and recursive neural networks
  process hierarchical structure}.
\newblock In \emph{Proceedings of the Twenty-Seventh International Joint
  Conference on Artificial Intelligence, {IJCAI} 2018, July 13-19, 2018,
  Stockholm, Sweden.}, pages 5617--5621.

\bibitem[{Je\v{z}ek(2016)}]{Jezek:2016}
Elisabetta Je\v{z}ek. 2016.
\newblock \emph{The Lexicon: An Introduction}.
\newblock Oxford University Press, Oxford, UK.

\bibitem[{K\`ad\`ar et~al.(2017)K\`ad\`ar, Chrupa\l{}a, and
  Alishahi}]{Kadar:etal:2017}
\`Akos K\`ad\`ar, Grzegorz Chrupa\l{}a, and Afra Alishahi. 2017.
\newblock Representation of linguistic form and function in recurrent neural
  networks.
\newblock \emph{Computational Linguistics}, 43(4):761--780.

\bibitem[{Kann et~al.(2016)Kann, Cotterell, and Sch{\"u}tze}]{Kann:etal:2016}
Katharina Kann, Ryan Cotterell, and Hinrich Sch{\"u}tze. 2016.
\newblock Neural morphological analysis: Encoding-decoding canonical segments.
\newblock In \emph{Proceedings of EMNLP}, pages 961--967, Austin, Texas.

\bibitem[{Kementchedjhieva and Lopez(2018)}]{Kementchedjhieva:Lopez:2018}
Yova Kementchedjhieva and Adam Lopez. 2018.
\newblock {`Indicatements'} that character language models learn {English}
  morpho-syntactic units and regularities.
\newblock In \emph{Proceedings of the EMNLP Workshop on analyzing and
  interpreting neural networks for {NLP}}, Brussels, Belgium.
\newblock {I}n press.

\bibitem[{Kim et~al.(2016)Kim, Jernite, Sontag, and Rush}]{Kim:etal:2016}
Yoon Kim, Yacine Jernite, David Sontag, and Alexander Rush. 2016.
\newblock Character-aware neural language models.
\newblock In \emph{Proceedings of AAAI}, pages 2741--2749, Phoenix, AZ.

\bibitem[{Kirov and Cotterell(2018)}]{Kirov:Cotterell:2018}
Christo Kirov and Ryan Cotterell. 2018.
\newblock Recurrent neural networks in linguistic theory: Revisiting {Pinker
  and Prince} (1988) and the past tense debate.
\newblock \emph{Transactions of the Association for Computational Linguistics}.
\newblock {I}n press.

\bibitem[{Kuhl(2004)}]{Kuhl:2004}
Patricia Kuhl. 2004.
\newblock Early language acquisition: Cracking the speech code.
\newblock \emph{Nature Reviews Neuroscience}, 5(11):831--843.

\bibitem[{Lau et~al.(2017)Lau, Clark, and Lappin}]{Lau:etal:2017}
Jey~Han Lau, Alexander Clark, and Shalom Lappin. 2017.
\newblock Grammaticality, acceptability, and probability: A probabilistic view
  of linguistic knowledge.
\newblock \emph{Cognitive Science}, 41(5):1202--1241.

\bibitem[{Li et~al.(2016)Li, Chen, Hovy, and Jurafsky}]{Li:etal:2016}
Jiwei Li, Xinlei Chen, Eduard Hovy, and Dan Jurafsky. 2016.
\newblock Visualizing and understanding neural models in {NLP}.
\newblock In \emph{Proceedings of NAACL}, pages 681--691, San Diego, CA.

\bibitem[{Li et~al.(2017)Li, Monroe, and Jurafsky}]{DBLP:journals/corr/LiMJ16a}
Jiwei Li, Will Monroe, and Dan Jurafsky. 2017.
\newblock \href {http://arxiv.org/abs/1612.08220} {Understanding neural
  networks through representation erasure}.
\newblock \emph{CoRR}, abs/1612.08220v3.

\bibitem[{Linzen et~al.(2016)Linzen, Dupoux, and Goldberg}]{Linzen:etal:2016}
Tal Linzen, Emmanuel Dupoux, and Yoav Goldberg. 2016.
\newblock Assessing the ability of {LSTM}s to learn syntax-sensitive
  dependencies.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  4:521--535.

\bibitem[{Maye et~al.(2002)Maye, Werker, and Gerken}]{Maye:etal:2002}
Jessica Maye, Janet Werker, and LouAnn Gerken. 2002.
\newblock Infant sensitivity to distributional information can affect phonetic
  discrimination.
\newblock \emph{Cognition}, 82(3):B101--B111.

\bibitem[{McCoy et~al.(2018)McCoy, Frank, and Linzen}]{McCoy:etal:2018}
Thomas McCoy, Robert Frank, and Tal Linzen. 2018.
\newblock Revisiting the poverty of the stimulus: Hierarchical generalization
  without a hierarchical bias in recurrent neural networks.
\newblock In \emph{Proceedings of CogSci}, pages 2093--2098, Madison, WI.

\bibitem[{McDonald et~al.(2013)McDonald, Nivre, Quirmbach-Brundage, Goldberg,
  Das, Ganchev, Hall, Petrov, Zhang, T{\"a}ckstr{\"o}m
  et~al.}]{mcdonald2013universal}
Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-Brundage, Yoav Goldberg, Dipanjan
  Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar
  T{\"a}ckstr{\"o}m, et~al. 2013.
\newblock Universal dependency annotation for multilingual parsing.
\newblock In \emph{Proceedings of the 51st Annual Meeting of the Association
  for Computational Linguistics (Volume 2: Short Papers)}, volume~2, pages
  92--97.

\bibitem[{Melamud et~al.(2016)Melamud, Goldberger, and
  Dagan}]{melamud2016context2vec}
Oren Melamud, Jacob Goldberger, and Ido Dagan. 2016.
\newblock context2vec: Learning generic context embedding with bidirectional
  lstm.
\newblock In \emph{Proceedings of The 20th SIGNLL Conference on Computational
  Natural Language Learning}, pages 51--61.

\bibitem[{Merity et~al.(2018)Merity, Keskar, and Socher}]{merity2018analysis}
Stephen Merity, Nitish~Shirish Keskar, and Richard Socher. 2018.
\newblock An analysis of neural language modeling at multiple scales.
\newblock \emph{arXiv preprint arXiv:1803.08240}.

\bibitem[{Mikolov(2012)}]{Mikolov:2012}
Tomas Mikolov. 2012.
\newblock \emph{Statistical language models based on neural networks}.
\newblock Dissertation, Brno University of Technology.

\bibitem[{Mikolov et~al.(2013{\natexlab{a}})Mikolov, Chen, Corrado, and
  Dean}]{DBLP:journals/corr/abs-1301-3781}
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013{\natexlab{a}}.
\newblock \href {http://arxiv.org/abs/1301.3781} {Efficient estimation of word
  representations in vector space}.
\newblock \emph{CoRR}, abs/1301.3781.

\bibitem[{Mikolov et~al.(2011)Mikolov, Sutskever, Deoras, Le, Kombrink, and
  Cernock{\'{y}}}]{Mikolov:etal:2011}
Tomas Mikolov, Ilya Sutskever, Anoop Deoras, Hai-Son Le, Stefan Kombrink, and
  Jan Cernock{\'{y}}. 2011.
\newblock Subword language modeling with neural networks.
\newblock \url{http://www.fit.vutbr.cz/~imikolov/rnnlm/}.

\bibitem[{Mikolov et~al.(2013{\natexlab{b}})Mikolov, Yih, and
  Zweig}]{Mikolov:etal:2013a}
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013{\natexlab{b}}.
\newblock Linguistic regularities in continuous space word representations.
\newblock In \emph{Proceedings of NAACL}, pages 746--751, Atlanta, Georgia.

\bibitem[{Pater(2018)}]{Pater:2018}
Joe Pater. 2018.
\newblock Generative linguistics and neural networks at 60: Foundation,
  friction, and fusion.
\newblock \emph{Language}.
\newblock {I}n press.

\bibitem[{Petrov and Klein(2007)}]{petrov2007improved}
Slav Petrov and Dan Klein. 2007.
\newblock Improved inference for unlexicalized parsing.
\newblock In \emph{Human Language Technologies 2007: The Conference of the
  North American Chapter of the Association for Computational Linguistics;
  Proceedings of the Main Conference}, pages 404--411.

\bibitem[{Radford et~al.(2017)Radford, J{\'{o}}zefowicz, and
  Sutskever}]{DBLP:journals/corr/RadfordJS17}
Alec Radford, Rafal J{\'{o}}zefowicz, and Ilya Sutskever. 2017.
\newblock \href {http://arxiv.org/abs/1704.01444} {Learning to generate reviews
  and discovering sentiment}.
\newblock \emph{CoRR}, abs/1704.01444.

\bibitem[{Radford(2006)}]{Radford:2006}
Andrew Radford. 2006.
\newblock Minimalist syntax revisited.
\newblock \url{http://www.public.asu.edu/~gelderen/Radford2009.pdf}.

\bibitem[{Saffran et~al.(1996)Saffran, Newport, and Aslin}]{saffran-word-1996}
Jenny~R Saffran, Elissa~L Newport, and Richard~N Aslin. 1996.
\newblock Word segmentation: {The} role of distributional cues.
\newblock \emph{Journal of memory and language}, 35(4):606--621.

\bibitem[{Sag et~al.(2003)Sag, Wasow, and Bender}]{Sag:etal:2003}
Ivan Sag, Thomas Wasow, and Emily Bender. 2003.
\newblock \emph{Syntactic Theory: A Formal Introduction}.
\newblock CSLI, Stanford, CA.

\bibitem[{Sennrich(2017)}]{Sennrich:2017}
Rico Sennrich. 2017.
\newblock How grammatical is character-level neural machine translation?
  assessing {MT} quality with contrastive translation pairs.
\newblock In \emph{Proceedings of EACL (Short Papers)}, pages 376--382,
  Valencia, Spain.

\bibitem[{Shi et~al.(2016)Shi, Padhi, and Knight}]{Shi:etal:2016}
Xing Shi, Inkit Padhi, and Kevin Knight. 2016.
\newblock Does string-based neural {MT} learn source syntax?
\newblock In \emph{Proceedings of EMNLP}, pages 1526--1534, Austin, Texas.

\bibitem[{Sun et~al.(1998)Sun, Dayang, and Tsou}]{sun-chinese-1998}
Maosung Sun, Shen Dayang, and Benjamin~K Tsou. 1998.
\newblock Chinese word segmentation without using lexicon and hand-crafted
  training data.
\newblock In \emph{Proceedings of the 36th {Annual} {Meeting} of the
  {Association} for {Computational} {Linguistics} and 17th {International}
  {Conference} on {Computational} {Linguistics}-{Volume} 2}, pages 1265--1271.
  Association for Computational Linguistics.

\bibitem[{Sutskever et~al.(2011)Sutskever, Martens, and
  Hinton}]{Sutskever:etal:2011}
Ilya Sutskever, James Martens, and Geoffrey Hinton. 2011.
\newblock Generating text with recurrent neural networks.
\newblock In \emph{Proceedings of ICML}, pages 1017--1024, Bellevue, WA.

\bibitem[{Woods(2016)}]{woods2016exploiting}
Aubrie Woods. 2016.
\newblock Exploiting linguistic features for sentence completion.
\newblock In \emph{Proceedings of the 54th Annual Meeting of the Association
  for Computational Linguistics (Volume 2: Short Papers)}, volume~2, pages
  438--442.

\bibitem[{Zhang et~al.(2016)Zhang, Lu, and Lapata}]{zhang2016top}
Xingxing Zhang, Liang Lu, and Mirella Lapata. 2016.
\newblock Top-down tree long short-term memory networks.
\newblock In \emph{Proceedings of the 2016 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 310--320.

\bibitem[{Zweig and Burges(2011)}]{Zweig:Burges:2011}
Geoffrey Zweig and Christopher Burges. 2011.
\newblock The {Microsoft Research} sentence completion challenge.
\newblock Technical Report MSR-TR-2011-129, Microsoft Research.

\bibitem[{Zweig et~al.(2012)Zweig, Platt, Meek, Burges, Yessenalina, and
  Liu}]{zweig2012computational}
Geoffrey Zweig, John~C Platt, Christopher Meek, Christopher~JC Burges, Ainur
  Yessenalina, and Qiang Liu. 2012.
\newblock Computational approaches to sentence completion.
\newblock In \emph{Proceedings of the 50th Annual Meeting of the Association
  for Computational Linguistics: Long Papers-Volume 1}, pages 601--610.
  Association for Computational Linguistics.

\end{thebibliography}
